{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNJ7OSCk1dIT"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
        "\n",
        "## Unit 2: Building User Interfaces with Gradio\n",
        "\n",
        "**CV Raman Global University, Bhubaneswar**  \n",
        "*AI Center of Excellence*\n",
        "\n",
        "---\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Poorit-Technologies/cvraman-coe/blob/main/courses-contents/ai-systems-engineering-1/unit-2/01-ai-systems-engineering-1-unit2-gradio-ui-basics.ipynb)\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "1. **Build user interfaces with Gradio** - the simplest way to create ML demos\n",
        "2. **Create streaming LLM interfaces** for better user experience\n",
        "3. **Add model selection dropdowns** to switch between providers\n",
        "4. **Build a company pamphlet generator UI** as a practical project\n",
        "\n",
        "**Duration:** ~1.5 hours\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVG9gT3J1dIa"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4athKnKt1dIc"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q openai gradio requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "68UupQG11dIe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MftMz3X1dIg",
        "outputId": "69f90095-2b30-4ec4-b7f6-7d085157f0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: ··········\n",
            "Enter your Google API Key (or press Enter to skip): ··········\n"
          ]
        }
      ],
      "source": [
        "# Configure API keys\n",
        "openai_api_key = getpass(\"Enter your OpenAI API Key: \")\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "# Optional: Google API key for Gemini\n",
        "google_api_key = getpass(\"Enter your Google API Key (or press Enter to skip): \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AwJRHKg51dIh"
      },
      "outputs": [],
      "source": [
        "# Initialize clients\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "GEMINI_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "gemini_client = OpenAI(api_key=google_api_key, base_url=GEMINI_URL) if google_api_key else None\n",
        "\n",
        "MODEL = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnNFJBg1dIj"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Your First Gradio Interface\n",
        "\n",
        "Gradio makes it incredibly simple to create web UIs for Python functions.\n",
        "\n",
        "The basic pattern is:\n",
        "```python\n",
        "gr.Interface(fn=your_function, inputs=\"textbox\", outputs=\"textbox\").launch()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0zunAHrq1dIj"
      },
      "outputs": [],
      "source": [
        "# A simple function to demonstrate\n",
        "def shout(text):\n",
        "    return text.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0Cde2O0-1dIk",
        "outputId": "d9f633a7-d9d6-4c86-c7de-41d74efc4c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2b67df8ee8f1d2adb6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2b67df8ee8f1d2adb6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create a Gradio interface\n",
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgXDNm3O1dIl"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Connecting to an LLM\n",
        "\n",
        "Let's wrap our LLM call in a function and connect it to Gradio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Djnp6tev1dIm"
      },
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant that responds in markdown.\"\n",
        "\n",
        "def message_gpt(prompt):\n",
        "    \"\"\"Send a message to GPT and return the response.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    response = openai_client.chat.completions.create(model=MODEL, messages=messages)\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "zuzfG0os1dIn",
        "outputId": "6ee69ff3-c078-42dc-e2eb-f6e1e53034b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://94fc04109e8c315687.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://94fc04109e8c315687.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Create a more polished interface\n",
        "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
        "message_output = gr.Markdown(label=\"Response:\")\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=message_gpt,\n",
        "    title=\"GPT Assistant\",\n",
        "    inputs=[message_input],\n",
        "    outputs=[message_output],\n",
        "    examples=[\n",
        "        \"Explain machine learning in simple terms\",\n",
        "        \"What is the capital of India?\"\n",
        "    ],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNIRsFxp1dIo"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Streaming Responses\n",
        "\n",
        "Streaming shows the response as it's generated, providing a much better user experience.\n",
        "\n",
        "We use Python **generators** (the `yield` keyword) for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azVbXDZJ1dIo"
      },
      "outputs": [],
      "source": [
        "def stream_gpt(prompt):\n",
        "    \"\"\"Stream a response from GPT.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    stream = openai_client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz1yeSL11dIp"
      },
      "outputs": [],
      "source": [
        "# Streaming interface\n",
        "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
        "message_output = gr.Markdown(label=\"Response:\")\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=stream_gpt,\n",
        "    title=\"GPT Assistant (Streaming)\",\n",
        "    inputs=[message_input],\n",
        "    outputs=[message_output],\n",
        "    examples=[\n",
        "        \"Explain the Transformer architecture to a beginner\",\n",
        "        \"Write a short poem about coding\"\n",
        "    ],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFw7Scnq1dIq"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Model Selection Dropdown\n",
        "\n",
        "Let's add the ability to choose between different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hUqZyE81dIq"
      },
      "outputs": [],
      "source": [
        "def stream_gemini(prompt):\n",
        "    \"\"\"Stream a response from Gemini.\"\"\"\n",
        "    if not gemini_client:\n",
        "        yield \"Gemini API key not configured.\"\n",
        "        return\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    stream = gemini_client.chat.completions.create(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf4lIZO91dIr"
      },
      "outputs": [],
      "source": [
        "def stream_model(prompt, model):\n",
        "    \"\"\"Stream response from selected model.\"\"\"\n",
        "    if model == \"GPT\":\n",
        "        yield from stream_gpt(prompt)\n",
        "    elif model == \"Gemini\":\n",
        "        yield from stream_gemini(prompt)\n",
        "    else:\n",
        "        yield \"Unknown model selected.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d73w4ONJ1dI3"
      },
      "outputs": [],
      "source": [
        "# Interface with model selection\n",
        "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
        "model_selector = gr.Dropdown([\"GPT\", \"Gemini\"], label=\"Select model\", value=\"GPT\")\n",
        "message_output = gr.Markdown(label=\"Response:\")\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=stream_model,\n",
        "    title=\"Multi-Model Assistant\",\n",
        "    inputs=[message_input, model_selector],\n",
        "    outputs=[message_output],\n",
        "    examples=[\n",
        "        [\"What is deep learning?\", \"GPT\"],\n",
        "        [\"Explain neural networks\", \"Gemini\"]\n",
        "    ],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELq8-JBX1dI5"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Project: Company Pamphlet Generator\n",
        "\n",
        "Let's build a practical application that scrapes a company website and generates a pamphlet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B0sBxro1dI5"
      },
      "outputs": [],
      "source": [
        "# Web scraping utility\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
        "}\n",
        "\n",
        "def fetch_website_contents(url, max_chars=2000):\n",
        "    \"\"\"Fetch and return the text content of a website.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        title = soup.title.string if soup.title else \"No title found\"\n",
        "\n",
        "        if soup.body:\n",
        "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "                irrelevant.decompose()\n",
        "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "        else:\n",
        "            text = \"\"\n",
        "\n",
        "        return (title + \"\\n\\n\" + text)[:max_chars]\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching website: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyH84Ly41dI6"
      },
      "outputs": [],
      "source": [
        "# Update system message for pamphlet generation\n",
        "pamphlet_system = \"\"\"\n",
        "You are an assistant that analyzes company website content\n",
        "and creates a short pamphlet for prospective customers, investors and recruits.\n",
        "Respond in markdown without code blocks.\n",
        "\"\"\"\n",
        "\n",
        "def stream_pamphlet(company_name, url, model):\n",
        "    \"\"\"Generate a company pamphlet with streaming.\"\"\"\n",
        "    yield \"\"\n",
        "\n",
        "    website_content = fetch_website_contents(url)\n",
        "    prompt = f\"Please generate a company pamphlet for {company_name}. Here is their landing page:\\n{website_content}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": pamphlet_system},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    if model == \"GPT\":\n",
        "        client = openai_client\n",
        "        model_name = MODEL\n",
        "    else:\n",
        "        if not gemini_client:\n",
        "            yield \"Gemini API key not configured.\"\n",
        "            return\n",
        "        client = gemini_client\n",
        "        model_name = \"gemini-1.5-flash\"\n",
        "\n",
        "    stream = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    result = \"\"\n",
        "    for chunk in stream:\n",
        "        result += chunk.choices[0].delta.content or \"\"\n",
        "        yield result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQPDCGxY1dI6"
      },
      "outputs": [],
      "source": [
        "# Pamphlet generator interface\n",
        "name_input = gr.Textbox(label=\"Company name:\")\n",
        "url_input = gr.Textbox(label=\"Landing page URL (include https://):\")\n",
        "model_selector = gr.Dropdown([\"GPT\", \"Gemini\"], label=\"Select model\", value=\"GPT\")\n",
        "pamphlet_output = gr.Markdown(label=\"Generated Pamphlet:\")\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=stream_pamphlet,\n",
        "    title=\"Company Pamphlet Generator\",\n",
        "    inputs=[name_input, url_input, model_selector],\n",
        "    outputs=[pamphlet_output],\n",
        "    examples=[\n",
        "        [\"Anthropic\", \"https://anthropic.com\", \"GPT\"],\n",
        "        [\"Hugging Face\", \"https://huggingface.co\", \"Gemini\"]\n",
        "    ],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjaRh9fZ1dI7"
      },
      "source": [
        "---\n",
        "\n",
        "## 7. Exercise: Build a Product Description Generator\n",
        "\n",
        "Create a Gradio interface that takes a product URL and generates marketing copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYMlkAvU1dI7"
      },
      "outputs": [],
      "source": [
        "# Exercise: Create a product description generator\n",
        "# 1. Define a system prompt for marketing copy\n",
        "# 2. Create a streaming function that fetches product page and generates description\n",
        "# 3. Build a Gradio interface\n",
        "\n",
        "# Your implementation here\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkYxpviz1dI7"
      },
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Gradio makes UI creation simple** - just wrap your function with `gr.Interface`\n",
        "\n",
        "2. **Streaming improves UX** - use generators (`yield`) for real-time output\n",
        "\n",
        "3. **Dropdowns add flexibility** - easily switch between models or options\n",
        "\n",
        "4. **Combine scraping + LLM** - powerful pattern for content generation\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "In the next notebook, we'll explore:\n",
        "- Building conversational AI with memory\n",
        "- ChatInterface for chatbot UIs\n",
        "- System prompts for context\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "- [Gradio Documentation](https://www.gradio.app/guides/quickstart)\n",
        "- [Gradio Components](https://www.gradio.app/docs/components)\n",
        "\n",
        "---\n",
        "\n",
        "**Course Information:**\n",
        "- **Institution:** CV Raman Global University, Bhubaneswar\n",
        "- **Program:** AI Center of Excellence\n",
        "- **Course:** AI Systems Engineering 1\n",
        "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}